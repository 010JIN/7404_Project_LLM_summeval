{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/mac/.cursor-tutor/7404_Project /7404_Project_LLM_summeval\n"
     ]
    }
   ],
   "source": [
    "cd 7404_Project_LLM_summeval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Large Language Models are Not Yet Human-Level Evaluators for Abstractive Summarization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Refer: \n",
    "https://github.com/DAMO-NLP-SG/LLM_summeval.git\n",
    "\n",
    "Authors: Chenhui Shen, Liying Cheng, Xuan-Phi Nguyen, Yang You and Lidong Bing\n",
    "\n",
    "This repository contains code and related resources of the paper \"Large Language Models are Not Yet Human-Level Evaluators for Abstractive Summarization\".\n",
    "\n",
    "\n",
    "@inproceedings{shen2023llmeval,\n",
    "  title={Large Language Models are Not Yet Human-Level Evaluators for Abstractive Summarization},\n",
    "  author={Shen, Chenhui and Cheng, Liying and Nguyen, Xuan-Phi and Bing, Lidong and You, Yang},\n",
    "  booktitle={Findings of EMNLP},\n",
    "  url={\"https://arxiv.org/abs/2305.13091\"},\n",
    "  year={2023}\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Set up the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into '7404_Project_LLM_summeval'...\n",
      "remote: Enumerating objects: 695, done.\u001b[K\n",
      "remote: Counting objects: 100% (695/695), done.\u001b[K\n",
      "remote: Compressing objects: 100% (135/135), done.\u001b[K\n",
      "remote: Total 695 (delta 563), reused 672 (delta 553), pack-reused 0\u001b[K\n",
      "Receiving objects: 100% (695/695), 6.81 MiB | 13.41 MiB/s, done.\n",
      "Resolving deltas: 100% (563/563), done.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/010JIN/7404_Project_LLM_summeval.git\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openai==0.28\n",
      "  Downloading openai-0.28.0-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: requests>=2.20 in /opt/anaconda3/envs/pytorch/lib/python3.9/site-packages (from openai==0.28) (2.31.0)\n",
      "Requirement already satisfied: tqdm in /opt/anaconda3/envs/pytorch/lib/python3.9/site-packages (from openai==0.28) (4.66.2)\n",
      "Requirement already satisfied: aiohttp in /opt/anaconda3/envs/pytorch/lib/python3.9/site-packages (from openai==0.28) (3.9.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/envs/pytorch/lib/python3.9/site-packages (from requests>=2.20->openai==0.28) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/envs/pytorch/lib/python3.9/site-packages (from requests>=2.20->openai==0.28) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/envs/pytorch/lib/python3.9/site-packages (from requests>=2.20->openai==0.28) (1.26.19)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/envs/pytorch/lib/python3.9/site-packages (from requests>=2.20->openai==0.28) (2024.2.2)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/anaconda3/envs/pytorch/lib/python3.9/site-packages (from aiohttp->openai==0.28) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/anaconda3/envs/pytorch/lib/python3.9/site-packages (from aiohttp->openai==0.28) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/anaconda3/envs/pytorch/lib/python3.9/site-packages (from aiohttp->openai==0.28) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/anaconda3/envs/pytorch/lib/python3.9/site-packages (from aiohttp->openai==0.28) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/anaconda3/envs/pytorch/lib/python3.9/site-packages (from aiohttp->openai==0.28) (1.9.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /opt/anaconda3/envs/pytorch/lib/python3.9/site-packages (from aiohttp->openai==0.28) (4.0.3)\n",
      "Downloading openai-0.28.0-py3-none-any.whl (76 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.5/76.5 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: openai\n",
      "  Attempting uninstall: openai\n",
      "    Found existing installation: openai 1.35.10\n",
      "    Uninstalling openai-1.35.10:\n",
      "      Successfully uninstalled openai-1.35.10\n",
      "Successfully installed openai-0.28.0\n"
     ]
    }
   ],
   "source": [
    "!pip install openai==0.28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tqdm in /opt/anaconda3/envs/pytorch/lib/python3.9/site-packages (4.66.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scipy in /opt/anaconda3/envs/pytorch/lib/python3.9/site-packages (1.13.1)\n",
      "Requirement already satisfied: numpy<2.3,>=1.22.4 in /opt/anaconda3/envs/pytorch/lib/python3.9/site-packages (from scipy) (1.26.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting secret\n",
      "  Downloading secret-0.8.tar.gz (8.5 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting boto3>=1.2.3 (from secret)\n",
      "  Downloading boto3-1.34.140-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting pycryptodome>=3.1 (from secret)\n",
      "  Downloading pycryptodome-3.20.0-cp35-abi3-macosx_10_9_universal2.whl.metadata (3.4 kB)\n",
      "Collecting tabulate>=0.7.5 (from secret)\n",
      "  Downloading tabulate-0.9.0-py3-none-any.whl.metadata (34 kB)\n",
      "Requirement already satisfied: pytest>=2.8.5 in /opt/anaconda3/envs/pytorch/lib/python3.9/site-packages (from secret) (8.2.1)\n",
      "Requirement already satisfied: six in /opt/anaconda3/envs/pytorch/lib/python3.9/site-packages (from secret) (1.16.0)\n",
      "Collecting botocore<1.35.0,>=1.34.140 (from boto3>=1.2.3->secret)\n",
      "  Downloading botocore-1.34.140-py3-none-any.whl.metadata (5.7 kB)\n",
      "Collecting jmespath<2.0.0,>=0.7.1 (from boto3>=1.2.3->secret)\n",
      "  Downloading jmespath-1.0.1-py3-none-any.whl.metadata (7.6 kB)\n",
      "Collecting s3transfer<0.11.0,>=0.10.0 (from boto3>=1.2.3->secret)\n",
      "  Downloading s3transfer-0.10.2-py3-none-any.whl.metadata (1.7 kB)\n",
      "Requirement already satisfied: iniconfig in /opt/anaconda3/envs/pytorch/lib/python3.9/site-packages (from pytest>=2.8.5->secret) (2.0.0)\n",
      "Requirement already satisfied: packaging in /opt/anaconda3/envs/pytorch/lib/python3.9/site-packages (from pytest>=2.8.5->secret) (24.0)\n",
      "Requirement already satisfied: pluggy<2.0,>=1.5 in /opt/anaconda3/envs/pytorch/lib/python3.9/site-packages (from pytest>=2.8.5->secret) (1.5.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.0rc8 in /opt/anaconda3/envs/pytorch/lib/python3.9/site-packages (from pytest>=2.8.5->secret) (1.2.0)\n",
      "Requirement already satisfied: tomli>=1 in /opt/anaconda3/envs/pytorch/lib/python3.9/site-packages (from pytest>=2.8.5->secret) (2.0.1)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /opt/anaconda3/envs/pytorch/lib/python3.9/site-packages (from botocore<1.35.0,>=1.34.140->boto3>=1.2.3->secret) (2.9.0)\n",
      "Collecting urllib3<1.27,>=1.25.4 (from botocore<1.35.0,>=1.34.140->boto3>=1.2.3->secret)\n",
      "  Downloading urllib3-1.26.19-py2.py3-none-any.whl.metadata (49 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.3/49.3 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading boto3-1.34.140-py3-none-any.whl (139 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.2/139.2 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pycryptodome-3.20.0-cp35-abi3-macosx_10_9_universal2.whl (2.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m34.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading tabulate-0.9.0-py3-none-any.whl (35 kB)\n",
      "Downloading botocore-1.34.140-py3-none-any.whl (12.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.4/12.4 MB\u001b[0m \u001b[31m34.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
      "Downloading s3transfer-0.10.2-py3-none-any.whl (82 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.7/82.7 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading urllib3-1.26.19-py2.py3-none-any.whl (143 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.9/143.9 kB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: secret\n",
      "  Building wheel for secret (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for secret: filename=secret-0.8-py3-none-any.whl size=9082 sha256=9e8728ff9db8e6538da8efcd106bb95e566c1b7965a1eda2866d79df436beab6\n",
      "  Stored in directory: /Users/mac/Library/Caches/pip/wheels/58/aa/49/392eef7d8ce149344fbacfeebff380a525cdd552d18c88ee8d\n",
      "Successfully built secret\n",
      "Installing collected packages: urllib3, tabulate, pycryptodome, jmespath, botocore, s3transfer, boto3, secret\n",
      "  Attempting uninstall: urllib3\n",
      "    Found existing installation: urllib3 2.1.0\n",
      "    Uninstalling urllib3-2.1.0:\n",
      "      Successfully uninstalled urllib3-2.1.0\n",
      "Successfully installed boto3-1.34.140 botocore-1.34.140 jmespath-1.0.1 pycryptodome-3.20.0 s3transfer-0.10.2 secret-0.8 tabulate-0.9.0 urllib3-1.26.19\n"
     ]
    }
   ],
   "source": [
    "!pip install secret"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Set the openai key:\n",
    "Creat a file named secret.py and set the openai key in format: my_key = 'XXX'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Demo:\n",
    "#### This demo only use gpt-3.5-turbo-0301 as evaluation model.\n",
    "\n",
    "For RTS or MCQ\n",
    "- Step 1: Get RTS or MCQ response from openai APIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval_model: gpt-3.5-turbo-0301\n",
      "dim: 0\n",
      "eval_type: 0\n",
      "start_idx: 0\n",
      "end_idx: 100\n",
      "print_full_prompt_without_calling_api: True\n",
      "M8\n",
      "eval relevance\n",
      "  0%|                                                   | 0/100 [00:00<?, ?it/s]prompt:\n",
      "Score the following Summary given the corresponding Article with respect to relevance from one to five, where one indicates \"irrelevance\", and five indicates \"perfect relevance\". Note that relevance measures the Summary's selection of important content from the Article, whether the Summary grasps the main message of the Article without being overwhelmed by unnecessary or less significant details.\n",
      "\n",
      "Article: Paul Merson has restarted his row with Andros Townsend after the Tottenham midfielder was brought on with only seven minutes remaining in his team's 0-0 draw with Burnley on Sunday. 'Just been watching the game, did you miss the coach? #RubberDub #7minutes,' Merson put on Twitter. Merson initially angered Townsend for writing in his Sky Sports column that 'if Andros Townsend can get in (the England team) then it opens it up to anybody.' Paul Merson had another dig at Andros Townsend after his appearance for Tottenham against Burnley Townsend was brought on in the 83rd minute for Tottenham as they drew 0-0 against Burnley Andros Townsend scores England's equaliser in their 1-1 friendly draw with Italy in Turin on Tuesday night The former Arsenal man was proven wrong when Townsend hit a stunning equaliser for England against Italy and he duly admitted his mistake. 'It's not as though I was watching hoping he wouldn't score for England, I'm genuinely pleased for him and fair play to him – it was a great goal,' Merson said. 'It's just a matter of opinion, and my opinion was that he got pulled off after half an hour at Manchester United in front of Roy Hodgson, so he shouldn't have been in the squad. 'When I'm wrong, I hold my hands up. I don't have a problem with doing that - I'll always be the first to admit when I'm wrong.' Townsend hit back at Merson on Twitter after scoring for England against Italy Sky Sports pundit  Merson (centre) criticised Townsend's call-up to the England squad last week Townsend hit back at Merson after netting for England in Turin on Wednesday, saying 'Not bad for a player that should be 'nowhere near the squad' ay @PaulMerse?' Any bad feeling between the pair seemed to have passed but Merson was unable to resist having another dig at Townsend after Tottenham drew at Turf Moor.\n",
      "\n",
      "Summary: paul merson has restarted his row with andros townsend after the tottenham midfielder was brought on with only seven minutes remaining in his team 's 0-0 draw with burnley . townsend was brought on in the 83rd minute for tottenham as they drew 0-0 against burnley . paul merson had another dig at andros townsend after scoring for england against italy .\n",
      "\n",
      "Provide your reason in one sentence, then give a final score:\n",
      "  0%|                                                   | 0/100 [00:00<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "# If you wish to see prompt first without calling the actual api, use flag --print_full_prompt_without_calling_api \n",
    "# For dim, 0 is relevance, 1 is consistency, 2 is fluency, and 3 is coherence;\n",
    "# For eval_type, 0 is RTS, 1 is MCQ, 2 is StarEval.\n",
    "# !python eval_with_rts_or_mcq.py --eval_model <openai model> --dim <int from 0 to 4> --eval_type <int from 0 to 3> \n",
    "# !python eval_with_rts_or_mcq.py --eval_model gpt-3.5-turbo-0301 --dim 0 --eval_type 0 \n",
    "!python eval_with_rts_or_mcq.py --eval_model gpt-3.5-turbo-0301 --dim 0 --eval_type 0 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Step 2: To compile a new data file with all metric results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval_model: gpt-3.5-turbo-0301\n",
      "M8\n",
      "extracting marks from:  eval_model_generations/gpt-3.5-turbo-0301/eval_M8_generations/relevance_rts.txt\n",
      "extracting marks from:  eval_model_generations/gpt-3.5-turbo-0301/eval_M8_generations/relevance_mcq.txt\n",
      "extracting marks from:  eval_model_generations/gpt-3.5-turbo-0301/eval_M8_generations/relevance_stareval.txt\n",
      "extracting marks from:  eval_model_generations/gpt-3.5-turbo-0301/eval_M8_generations/relevance_altrts.txt\n",
      "extracting marks from:  eval_model_generations/gpt-3.5-turbo-0301/eval_M8_generations/relevance_altmcq.txt\n",
      "extracting marks from:  eval_model_generations/gpt-3.5-turbo-0301/eval_M8_generations/consistency_rts.txt\n",
      "extracting marks from:  eval_model_generations/gpt-3.5-turbo-0301/eval_M8_generations/consistency_mcq.txt\n",
      "extracting marks from:  eval_model_generations/gpt-3.5-turbo-0301/eval_M8_generations/consistency_stareval.txt\n",
      "extracting marks from:  eval_model_generations/gpt-3.5-turbo-0301/eval_M8_generations/consistency_altrts.txt\n",
      "extracting marks from:  eval_model_generations/gpt-3.5-turbo-0301/eval_M8_generations/consistency_altmcq.txt\n",
      "extracting marks from:  eval_model_generations/gpt-3.5-turbo-0301/eval_M8_generations/fluency_rts.txt\n",
      "extracting marks from:  eval_model_generations/gpt-3.5-turbo-0301/eval_M8_generations/fluency_mcq.txt\n",
      "extracting marks from:  eval_model_generations/gpt-3.5-turbo-0301/eval_M8_generations/fluency_stareval.txt\n",
      "extracting marks from:  eval_model_generations/gpt-3.5-turbo-0301/eval_M8_generations/fluency_altrts.txt\n",
      "extracting marks from:  eval_model_generations/gpt-3.5-turbo-0301/eval_M8_generations/fluency_altmcq.txt\n",
      "extracting marks from:  eval_model_generations/gpt-3.5-turbo-0301/eval_M8_generations/coherence_rts.txt\n",
      "extracting marks from:  eval_model_generations/gpt-3.5-turbo-0301/eval_M8_generations/coherence_mcq.txt\n",
      "extracting marks from:  eval_model_generations/gpt-3.5-turbo-0301/eval_M8_generations/coherence_stareval.txt\n",
      "extracting marks from:  eval_model_generations/gpt-3.5-turbo-0301/eval_M8_generations/coherence_altrts.txt\n",
      "extracting marks from:  eval_model_generations/gpt-3.5-turbo-0301/eval_M8_generations/coherence_altmcq.txt\n",
      "M9\n",
      "extracting marks from:  eval_model_generations/gpt-3.5-turbo-0301/eval_M9_generations/relevance_rts.txt\n",
      "extracting marks from:  eval_model_generations/gpt-3.5-turbo-0301/eval_M9_generations/relevance_mcq.txt\n",
      "extracting marks from:  eval_model_generations/gpt-3.5-turbo-0301/eval_M9_generations/relevance_stareval.txt\n",
      "extracting marks from:  eval_model_generations/gpt-3.5-turbo-0301/eval_M9_generations/relevance_altrts.txt\n",
      "extracting marks from:  eval_model_generations/gpt-3.5-turbo-0301/eval_M9_generations/relevance_altmcq.txt\n",
      "extracting marks from:  eval_model_generations/gpt-3.5-turbo-0301/eval_M9_generations/consistency_rts.txt\n",
      "extracting marks from:  eval_model_generations/gpt-3.5-turbo-0301/eval_M9_generations/consistency_mcq.txt\n",
      "extracting marks from:  eval_model_generations/gpt-3.5-turbo-0301/eval_M9_generations/consistency_stareval.txt\n",
      "extracting marks from:  eval_model_generations/gpt-3.5-turbo-0301/eval_M9_generations/consistency_altrts.txt\n",
      "extracting marks from:  eval_model_generations/gpt-3.5-turbo-0301/eval_M9_generations/consistency_altmcq.txt\n",
      "extracting marks from:  eval_model_generations/gpt-3.5-turbo-0301/eval_M9_generations/fluency_rts.txt\n",
      "extracting marks from:  eval_model_generations/gpt-3.5-turbo-0301/eval_M9_generations/fluency_mcq.txt\n",
      "extracting marks from:  eval_model_generations/gpt-3.5-turbo-0301/eval_M9_generations/fluency_stareval.txt\n",
      "extracting marks from:  eval_model_generations/gpt-3.5-turbo-0301/eval_M9_generations/fluency_altrts.txt\n",
      "extracting marks from:  eval_model_generations/gpt-3.5-turbo-0301/eval_M9_generations/fluency_altmcq.txt\n",
      "extracting marks from:  eval_model_generations/gpt-3.5-turbo-0301/eval_M9_generations/coherence_rts.txt\n",
      "extracting marks from:  eval_model_generations/gpt-3.5-turbo-0301/eval_M9_generations/coherence_mcq.txt\n",
      "extracting marks from:  eval_model_generations/gpt-3.5-turbo-0301/eval_M9_generations/coherence_stareval.txt\n",
      "extracting marks from:  eval_model_generations/gpt-3.5-turbo-0301/eval_M9_generations/coherence_altrts.txt\n",
      "extracting marks from:  eval_model_generations/gpt-3.5-turbo-0301/eval_M9_generations/coherence_altmcq.txt\n",
      "M10\n",
      "extracting marks from:  eval_model_generations/gpt-3.5-turbo-0301/eval_M10_generations/relevance_rts.txt\n",
      "extracting marks from:  eval_model_generations/gpt-3.5-turbo-0301/eval_M10_generations/relevance_mcq.txt\n",
      "extracting marks from:  eval_model_generations/gpt-3.5-turbo-0301/eval_M10_generations/relevance_stareval.txt\n",
      "extracting marks from:  eval_model_generations/gpt-3.5-turbo-0301/eval_M10_generations/relevance_altrts.txt\n",
      "extracting marks from:  eval_model_generations/gpt-3.5-turbo-0301/eval_M10_generations/relevance_altmcq.txt\n",
      "extracting marks from:  eval_model_generations/gpt-3.5-turbo-0301/eval_M10_generations/consistency_rts.txt\n",
      "extracting marks from:  eval_model_generations/gpt-3.5-turbo-0301/eval_M10_generations/consistency_mcq.txt\n",
      "extracting marks from:  eval_model_generations/gpt-3.5-turbo-0301/eval_M10_generations/consistency_stareval.txt\n",
      "extracting marks from:  eval_model_generations/gpt-3.5-turbo-0301/eval_M10_generations/consistency_altrts.txt\n",
      "extracting marks from:  eval_model_generations/gpt-3.5-turbo-0301/eval_M10_generations/consistency_altmcq.txt\n",
      "extracting marks from:  eval_model_generations/gpt-3.5-turbo-0301/eval_M10_generations/fluency_rts.txt\n",
      "extracting marks from:  eval_model_generations/gpt-3.5-turbo-0301/eval_M10_generations/fluency_mcq.txt\n",
      "extracting marks from:  eval_model_generations/gpt-3.5-turbo-0301/eval_M10_generations/fluency_stareval.txt\n",
      "extracting marks from:  eval_model_generations/gpt-3.5-turbo-0301/eval_M10_generations/fluency_altrts.txt\n",
      "extracting marks from:  eval_model_generations/gpt-3.5-turbo-0301/eval_M10_generations/fluency_altmcq.txt\n",
      "extracting marks from:  eval_model_generations/gpt-3.5-turbo-0301/eval_M10_generations/coherence_rts.txt\n",
      "extracting marks from:  eval_model_generations/gpt-3.5-turbo-0301/eval_M10_generations/coherence_mcq.txt\n",
      "extracting marks from:  eval_model_generations/gpt-3.5-turbo-0301/eval_M10_generations/coherence_stareval.txt\n",
      "extracting marks from:  eval_model_generations/gpt-3.5-turbo-0301/eval_M10_generations/coherence_altrts.txt\n",
      "extracting marks from:  eval_model_generations/gpt-3.5-turbo-0301/eval_M10_generations/coherence_altmcq.txt\n",
      "M11\n",
      "extracting marks from:  eval_model_generations/gpt-3.5-turbo-0301/eval_M11_generations/relevance_rts.txt\n",
      "extracting marks from:  eval_model_generations/gpt-3.5-turbo-0301/eval_M11_generations/relevance_mcq.txt\n",
      "extracting marks from:  eval_model_generations/gpt-3.5-turbo-0301/eval_M11_generations/relevance_stareval.txt\n",
      "extracting marks from:  eval_model_generations/gpt-3.5-turbo-0301/eval_M11_generations/relevance_altrts.txt\n",
      "extracting marks from:  eval_model_generations/gpt-3.5-turbo-0301/eval_M11_generations/relevance_altmcq.txt\n",
      "extracting marks from:  eval_model_generations/gpt-3.5-turbo-0301/eval_M11_generations/consistency_rts.txt\n",
      "extracting marks from:  eval_model_generations/gpt-3.5-turbo-0301/eval_M11_generations/consistency_mcq.txt\n",
      "extracting marks from:  eval_model_generations/gpt-3.5-turbo-0301/eval_M11_generations/consistency_stareval.txt\n",
      "extracting marks from:  eval_model_generations/gpt-3.5-turbo-0301/eval_M11_generations/consistency_altrts.txt\n",
      "extracting marks from:  eval_model_generations/gpt-3.5-turbo-0301/eval_M11_generations/consistency_altmcq.txt\n",
      "extracting marks from:  eval_model_generations/gpt-3.5-turbo-0301/eval_M11_generations/fluency_rts.txt\n",
      "extracting marks from:  eval_model_generations/gpt-3.5-turbo-0301/eval_M11_generations/fluency_mcq.txt\n",
      "extracting marks from:  eval_model_generations/gpt-3.5-turbo-0301/eval_M11_generations/fluency_stareval.txt\n",
      "extracting marks from:  eval_model_generations/gpt-3.5-turbo-0301/eval_M11_generations/fluency_altrts.txt\n",
      "extracting marks from:  eval_model_generations/gpt-3.5-turbo-0301/eval_M11_generations/fluency_altmcq.txt\n",
      "extracting marks from:  eval_model_generations/gpt-3.5-turbo-0301/eval_M11_generations/coherence_rts.txt\n",
      "extracting marks from:  eval_model_generations/gpt-3.5-turbo-0301/eval_M11_generations/coherence_mcq.txt\n",
      "extracting marks from:  eval_model_generations/gpt-3.5-turbo-0301/eval_M11_generations/coherence_stareval.txt\n",
      "extracting marks from:  eval_model_generations/gpt-3.5-turbo-0301/eval_M11_generations/coherence_altrts.txt\n",
      "extracting marks from:  eval_model_generations/gpt-3.5-turbo-0301/eval_M11_generations/coherence_altmcq.txt\n",
      "M12\n",
      "extracting marks from:  eval_model_generations/gpt-3.5-turbo-0301/eval_M12_generations/relevance_rts.txt\n",
      "extracting marks from:  eval_model_generations/gpt-3.5-turbo-0301/eval_M12_generations/relevance_mcq.txt\n",
      "extracting marks from:  eval_model_generations/gpt-3.5-turbo-0301/eval_M12_generations/relevance_stareval.txt\n",
      "extracting marks from:  eval_model_generations/gpt-3.5-turbo-0301/eval_M12_generations/relevance_altrts.txt\n",
      "extracting marks from:  eval_model_generations/gpt-3.5-turbo-0301/eval_M12_generations/relevance_altmcq.txt\n",
      "extracting marks from:  eval_model_generations/gpt-3.5-turbo-0301/eval_M12_generations/consistency_rts.txt\n",
      "extracting marks from:  eval_model_generations/gpt-3.5-turbo-0301/eval_M12_generations/consistency_mcq.txt\n",
      "extracting marks from:  eval_model_generations/gpt-3.5-turbo-0301/eval_M12_generations/consistency_stareval.txt\n",
      "extracting marks from:  eval_model_generations/gpt-3.5-turbo-0301/eval_M12_generations/consistency_altrts.txt\n",
      "extracting marks from:  eval_model_generations/gpt-3.5-turbo-0301/eval_M12_generations/consistency_altmcq.txt\n",
      "extracting marks from:  eval_model_generations/gpt-3.5-turbo-0301/eval_M12_generations/fluency_rts.txt\n",
      "extracting marks from:  eval_model_generations/gpt-3.5-turbo-0301/eval_M12_generations/fluency_mcq.txt\n",
      "extracting marks from:  eval_model_generations/gpt-3.5-turbo-0301/eval_M12_generations/fluency_stareval.txt\n",
      "extracting marks from:  eval_model_generations/gpt-3.5-turbo-0301/eval_M12_generations/fluency_altrts.txt\n",
      "extracting marks from:  eval_model_generations/gpt-3.5-turbo-0301/eval_M12_generations/fluency_altmcq.txt\n",
      "extracting marks from:  eval_model_generations/gpt-3.5-turbo-0301/eval_M12_generations/coherence_rts.txt\n",
      "extracting marks from:  eval_model_generations/gpt-3.5-turbo-0301/eval_M12_generations/coherence_mcq.txt\n",
      "extracting marks from:  eval_model_generations/gpt-3.5-turbo-0301/eval_M12_generations/coherence_stareval.txt\n",
      "extracting marks from:  eval_model_generations/gpt-3.5-turbo-0301/eval_M12_generations/coherence_altrts.txt\n",
      "extracting marks from:  eval_model_generations/gpt-3.5-turbo-0301/eval_M12_generations/coherence_altmcq.txt\n",
      "M13\n",
      "extracting marks from:  eval_model_generations/gpt-3.5-turbo-0301/eval_M13_generations/relevance_rts.txt\n",
      "extracting marks from:  eval_model_generations/gpt-3.5-turbo-0301/eval_M13_generations/relevance_mcq.txt\n",
      "extracting marks from:  eval_model_generations/gpt-3.5-turbo-0301/eval_M13_generations/relevance_stareval.txt\n",
      "extracting marks from:  eval_model_generations/gpt-3.5-turbo-0301/eval_M13_generations/relevance_altrts.txt\n",
      "extracting marks from:  eval_model_generations/gpt-3.5-turbo-0301/eval_M13_generations/relevance_altmcq.txt\n",
      "extracting marks from:  eval_model_generations/gpt-3.5-turbo-0301/eval_M13_generations/consistency_rts.txt\n",
      "extracting marks from:  eval_model_generations/gpt-3.5-turbo-0301/eval_M13_generations/consistency_mcq.txt\n",
      "extracting marks from:  eval_model_generations/gpt-3.5-turbo-0301/eval_M13_generations/consistency_stareval.txt\n",
      "extracting marks from:  eval_model_generations/gpt-3.5-turbo-0301/eval_M13_generations/consistency_altrts.txt\n",
      "extracting marks from:  eval_model_generations/gpt-3.5-turbo-0301/eval_M13_generations/consistency_altmcq.txt\n",
      "extracting marks from:  eval_model_generations/gpt-3.5-turbo-0301/eval_M13_generations/fluency_rts.txt\n",
      "extracting marks from:  eval_model_generations/gpt-3.5-turbo-0301/eval_M13_generations/fluency_mcq.txt\n",
      "extracting marks from:  eval_model_generations/gpt-3.5-turbo-0301/eval_M13_generations/fluency_stareval.txt\n",
      "extracting marks from:  eval_model_generations/gpt-3.5-turbo-0301/eval_M13_generations/fluency_altrts.txt\n",
      "extracting marks from:  eval_model_generations/gpt-3.5-turbo-0301/eval_M13_generations/fluency_altmcq.txt\n",
      "extracting marks from:  eval_model_generations/gpt-3.5-turbo-0301/eval_M13_generations/coherence_rts.txt\n",
      "extracting marks from:  eval_model_generations/gpt-3.5-turbo-0301/eval_M13_generations/coherence_mcq.txt\n",
      "extracting marks from:  eval_model_generations/gpt-3.5-turbo-0301/eval_M13_generations/coherence_stareval.txt\n",
      "extracting marks from:  eval_model_generations/gpt-3.5-turbo-0301/eval_M13_generations/coherence_altrts.txt\n",
      "extracting marks from:  eval_model_generations/gpt-3.5-turbo-0301/eval_M13_generations/coherence_altmcq.txt\n",
      "M14\n",
      "extracting marks from:  eval_model_generations/gpt-3.5-turbo-0301/eval_M14_generations/relevance_rts.txt\n",
      "extracting marks from:  eval_model_generations/gpt-3.5-turbo-0301/eval_M14_generations/relevance_mcq.txt\n",
      "extracting marks from:  eval_model_generations/gpt-3.5-turbo-0301/eval_M14_generations/relevance_stareval.txt\n",
      "extracting marks from:  eval_model_generations/gpt-3.5-turbo-0301/eval_M14_generations/relevance_altrts.txt\n",
      "extracting marks from:  eval_model_generations/gpt-3.5-turbo-0301/eval_M14_generations/relevance_altmcq.txt\n",
      "extracting marks from:  eval_model_generations/gpt-3.5-turbo-0301/eval_M14_generations/consistency_rts.txt\n",
      "extracting marks from:  eval_model_generations/gpt-3.5-turbo-0301/eval_M14_generations/consistency_mcq.txt\n",
      "extracting marks from:  eval_model_generations/gpt-3.5-turbo-0301/eval_M14_generations/consistency_stareval.txt\n",
      "extracting marks from:  eval_model_generations/gpt-3.5-turbo-0301/eval_M14_generations/consistency_altrts.txt\n",
      "extracting marks from:  eval_model_generations/gpt-3.5-turbo-0301/eval_M14_generations/consistency_altmcq.txt\n",
      "extracting marks from:  eval_model_generations/gpt-3.5-turbo-0301/eval_M14_generations/fluency_rts.txt\n",
      "extracting marks from:  eval_model_generations/gpt-3.5-turbo-0301/eval_M14_generations/fluency_mcq.txt\n",
      "extracting marks from:  eval_model_generations/gpt-3.5-turbo-0301/eval_M14_generations/fluency_stareval.txt\n",
      "extracting marks from:  eval_model_generations/gpt-3.5-turbo-0301/eval_M14_generations/fluency_altrts.txt\n",
      "extracting marks from:  eval_model_generations/gpt-3.5-turbo-0301/eval_M14_generations/fluency_altmcq.txt\n",
      "extracting marks from:  eval_model_generations/gpt-3.5-turbo-0301/eval_M14_generations/coherence_rts.txt\n",
      "extracting marks from:  eval_model_generations/gpt-3.5-turbo-0301/eval_M14_generations/coherence_mcq.txt\n",
      "extracting marks from:  eval_model_generations/gpt-3.5-turbo-0301/eval_M14_generations/coherence_stareval.txt\n",
      "extracting marks from:  eval_model_generations/gpt-3.5-turbo-0301/eval_M14_generations/coherence_altrts.txt\n",
      "extracting marks from:  eval_model_generations/gpt-3.5-turbo-0301/eval_M14_generations/coherence_altmcq.txt\n",
      "M15\n",
      "extracting marks from:  eval_model_generations/gpt-3.5-turbo-0301/eval_M15_generations/relevance_rts.txt\n",
      "extracting marks from:  eval_model_generations/gpt-3.5-turbo-0301/eval_M15_generations/relevance_mcq.txt\n",
      "extracting marks from:  eval_model_generations/gpt-3.5-turbo-0301/eval_M15_generations/relevance_stareval.txt\n",
      "extracting marks from:  eval_model_generations/gpt-3.5-turbo-0301/eval_M15_generations/relevance_altrts.txt\n",
      "extracting marks from:  eval_model_generations/gpt-3.5-turbo-0301/eval_M15_generations/relevance_altmcq.txt\n",
      "extracting marks from:  eval_model_generations/gpt-3.5-turbo-0301/eval_M15_generations/consistency_rts.txt\n",
      "extracting marks from:  eval_model_generations/gpt-3.5-turbo-0301/eval_M15_generations/consistency_mcq.txt\n",
      "extracting marks from:  eval_model_generations/gpt-3.5-turbo-0301/eval_M15_generations/consistency_stareval.txt\n",
      "extracting marks from:  eval_model_generations/gpt-3.5-turbo-0301/eval_M15_generations/consistency_altrts.txt\n",
      "extracting marks from:  eval_model_generations/gpt-3.5-turbo-0301/eval_M15_generations/consistency_altmcq.txt\n",
      "extracting marks from:  eval_model_generations/gpt-3.5-turbo-0301/eval_M15_generations/fluency_rts.txt\n",
      "extracting marks from:  eval_model_generations/gpt-3.5-turbo-0301/eval_M15_generations/fluency_mcq.txt\n",
      "extracting marks from:  eval_model_generations/gpt-3.5-turbo-0301/eval_M15_generations/fluency_stareval.txt\n",
      "extracting marks from:  eval_model_generations/gpt-3.5-turbo-0301/eval_M15_generations/fluency_altrts.txt\n",
      "extracting marks from:  eval_model_generations/gpt-3.5-turbo-0301/eval_M15_generations/fluency_altmcq.txt\n",
      "extracting marks from:  eval_model_generations/gpt-3.5-turbo-0301/eval_M15_generations/coherence_rts.txt\n",
      "extracting marks from:  eval_model_generations/gpt-3.5-turbo-0301/eval_M15_generations/coherence_mcq.txt\n",
      "extracting marks from:  eval_model_generations/gpt-3.5-turbo-0301/eval_M15_generations/coherence_stareval.txt\n",
      "extracting marks from:  eval_model_generations/gpt-3.5-turbo-0301/eval_M15_generations/coherence_altrts.txt\n",
      "extracting marks from:  eval_model_generations/gpt-3.5-turbo-0301/eval_M15_generations/coherence_altmcq.txt\n",
      "M17\n",
      "extracting marks from:  eval_model_generations/gpt-3.5-turbo-0301/eval_M17_generations/relevance_rts.txt\n",
      "extracting marks from:  eval_model_generations/gpt-3.5-turbo-0301/eval_M17_generations/relevance_mcq.txt\n",
      "extracting marks from:  eval_model_generations/gpt-3.5-turbo-0301/eval_M17_generations/relevance_stareval.txt\n",
      "extracting marks from:  eval_model_generations/gpt-3.5-turbo-0301/eval_M17_generations/relevance_altrts.txt\n",
      "extracting marks from:  eval_model_generations/gpt-3.5-turbo-0301/eval_M17_generations/relevance_altmcq.txt\n",
      "extracting marks from:  eval_model_generations/gpt-3.5-turbo-0301/eval_M17_generations/consistency_rts.txt\n",
      "extracting marks from:  eval_model_generations/gpt-3.5-turbo-0301/eval_M17_generations/consistency_mcq.txt\n",
      "extracting marks from:  eval_model_generations/gpt-3.5-turbo-0301/eval_M17_generations/consistency_stareval.txt\n",
      "extracting marks from:  eval_model_generations/gpt-3.5-turbo-0301/eval_M17_generations/consistency_altrts.txt\n",
      "extracting marks from:  eval_model_generations/gpt-3.5-turbo-0301/eval_M17_generations/consistency_altmcq.txt\n",
      "extracting marks from:  eval_model_generations/gpt-3.5-turbo-0301/eval_M17_generations/fluency_rts.txt\n",
      "extracting marks from:  eval_model_generations/gpt-3.5-turbo-0301/eval_M17_generations/fluency_mcq.txt\n",
      "extracting marks from:  eval_model_generations/gpt-3.5-turbo-0301/eval_M17_generations/fluency_stareval.txt\n",
      "extracting marks from:  eval_model_generations/gpt-3.5-turbo-0301/eval_M17_generations/fluency_altrts.txt\n",
      "extracting marks from:  eval_model_generations/gpt-3.5-turbo-0301/eval_M17_generations/fluency_altmcq.txt\n",
      "extracting marks from:  eval_model_generations/gpt-3.5-turbo-0301/eval_M17_generations/coherence_rts.txt\n",
      "extracting marks from:  eval_model_generations/gpt-3.5-turbo-0301/eval_M17_generations/coherence_mcq.txt\n",
      "extracting marks from:  eval_model_generations/gpt-3.5-turbo-0301/eval_M17_generations/coherence_stareval.txt\n",
      "extracting marks from:  eval_model_generations/gpt-3.5-turbo-0301/eval_M17_generations/coherence_altrts.txt\n",
      "extracting marks from:  eval_model_generations/gpt-3.5-turbo-0301/eval_M17_generations/coherence_altmcq.txt\n",
      "M20\n",
      "extracting marks from:  eval_model_generations/gpt-3.5-turbo-0301/eval_M20_generations/relevance_rts.txt\n",
      "extracting marks from:  eval_model_generations/gpt-3.5-turbo-0301/eval_M20_generations/relevance_mcq.txt\n",
      "extracting marks from:  eval_model_generations/gpt-3.5-turbo-0301/eval_M20_generations/relevance_stareval.txt\n",
      "extracting marks from:  eval_model_generations/gpt-3.5-turbo-0301/eval_M20_generations/relevance_altrts.txt\n",
      "extracting marks from:  eval_model_generations/gpt-3.5-turbo-0301/eval_M20_generations/relevance_altmcq.txt\n",
      "extracting marks from:  eval_model_generations/gpt-3.5-turbo-0301/eval_M20_generations/consistency_rts.txt\n",
      "extracting marks from:  eval_model_generations/gpt-3.5-turbo-0301/eval_M20_generations/consistency_mcq.txt\n",
      "extracting marks from:  eval_model_generations/gpt-3.5-turbo-0301/eval_M20_generations/consistency_stareval.txt\n",
      "extracting marks from:  eval_model_generations/gpt-3.5-turbo-0301/eval_M20_generations/consistency_altrts.txt\n",
      "extracting marks from:  eval_model_generations/gpt-3.5-turbo-0301/eval_M20_generations/consistency_altmcq.txt\n",
      "extracting marks from:  eval_model_generations/gpt-3.5-turbo-0301/eval_M20_generations/fluency_rts.txt\n",
      "extracting marks from:  eval_model_generations/gpt-3.5-turbo-0301/eval_M20_generations/fluency_mcq.txt\n",
      "extracting marks from:  eval_model_generations/gpt-3.5-turbo-0301/eval_M20_generations/fluency_stareval.txt\n",
      "extracting marks from:  eval_model_generations/gpt-3.5-turbo-0301/eval_M20_generations/fluency_altrts.txt\n",
      "extracting marks from:  eval_model_generations/gpt-3.5-turbo-0301/eval_M20_generations/fluency_altmcq.txt\n",
      "extracting marks from:  eval_model_generations/gpt-3.5-turbo-0301/eval_M20_generations/coherence_rts.txt\n",
      "extracting marks from:  eval_model_generations/gpt-3.5-turbo-0301/eval_M20_generations/coherence_mcq.txt\n",
      "extracting marks from:  eval_model_generations/gpt-3.5-turbo-0301/eval_M20_generations/coherence_stareval.txt\n",
      "extracting marks from:  eval_model_generations/gpt-3.5-turbo-0301/eval_M20_generations/coherence_altrts.txt\n",
      "extracting marks from:  eval_model_generations/gpt-3.5-turbo-0301/eval_M20_generations/coherence_altmcq.txt\n",
      "M22\n",
      "extracting marks from:  eval_model_generations/gpt-3.5-turbo-0301/eval_M22_generations/relevance_rts.txt\n",
      "extracting marks from:  eval_model_generations/gpt-3.5-turbo-0301/eval_M22_generations/relevance_mcq.txt\n",
      "extracting marks from:  eval_model_generations/gpt-3.5-turbo-0301/eval_M22_generations/relevance_stareval.txt\n",
      "extracting marks from:  eval_model_generations/gpt-3.5-turbo-0301/eval_M22_generations/relevance_altrts.txt\n",
      "extracting marks from:  eval_model_generations/gpt-3.5-turbo-0301/eval_M22_generations/relevance_altmcq.txt\n",
      "extracting marks from:  eval_model_generations/gpt-3.5-turbo-0301/eval_M22_generations/consistency_rts.txt\n",
      "extracting marks from:  eval_model_generations/gpt-3.5-turbo-0301/eval_M22_generations/consistency_mcq.txt\n",
      "extracting marks from:  eval_model_generations/gpt-3.5-turbo-0301/eval_M22_generations/consistency_stareval.txt\n",
      "extracting marks from:  eval_model_generations/gpt-3.5-turbo-0301/eval_M22_generations/consistency_altrts.txt\n",
      "extracting marks from:  eval_model_generations/gpt-3.5-turbo-0301/eval_M22_generations/consistency_altmcq.txt\n",
      "extracting marks from:  eval_model_generations/gpt-3.5-turbo-0301/eval_M22_generations/fluency_rts.txt\n",
      "extracting marks from:  eval_model_generations/gpt-3.5-turbo-0301/eval_M22_generations/fluency_mcq.txt\n",
      "extracting marks from:  eval_model_generations/gpt-3.5-turbo-0301/eval_M22_generations/fluency_stareval.txt\n",
      "extracting marks from:  eval_model_generations/gpt-3.5-turbo-0301/eval_M22_generations/fluency_altrts.txt\n",
      "extracting marks from:  eval_model_generations/gpt-3.5-turbo-0301/eval_M22_generations/fluency_altmcq.txt\n",
      "extracting marks from:  eval_model_generations/gpt-3.5-turbo-0301/eval_M22_generations/coherence_rts.txt\n",
      "extracting marks from:  eval_model_generations/gpt-3.5-turbo-0301/eval_M22_generations/coherence_mcq.txt\n",
      "extracting marks from:  eval_model_generations/gpt-3.5-turbo-0301/eval_M22_generations/coherence_stareval.txt\n",
      "extracting marks from:  eval_model_generations/gpt-3.5-turbo-0301/eval_M22_generations/coherence_altrts.txt\n",
      "extracting marks from:  eval_model_generations/gpt-3.5-turbo-0301/eval_M22_generations/coherence_altmcq.txt\n",
      "M23\n",
      "extracting marks from:  eval_model_generations/gpt-3.5-turbo-0301/eval_M23_generations/relevance_rts.txt\n",
      "extracting marks from:  eval_model_generations/gpt-3.5-turbo-0301/eval_M23_generations/relevance_mcq.txt\n",
      "extracting marks from:  eval_model_generations/gpt-3.5-turbo-0301/eval_M23_generations/relevance_stareval.txt\n",
      "extracting marks from:  eval_model_generations/gpt-3.5-turbo-0301/eval_M23_generations/relevance_altrts.txt\n",
      "extracting marks from:  eval_model_generations/gpt-3.5-turbo-0301/eval_M23_generations/relevance_altmcq.txt\n",
      "extracting marks from:  eval_model_generations/gpt-3.5-turbo-0301/eval_M23_generations/consistency_rts.txt\n",
      "extracting marks from:  eval_model_generations/gpt-3.5-turbo-0301/eval_M23_generations/consistency_mcq.txt\n",
      "extracting marks from:  eval_model_generations/gpt-3.5-turbo-0301/eval_M23_generations/consistency_stareval.txt\n",
      "extracting marks from:  eval_model_generations/gpt-3.5-turbo-0301/eval_M23_generations/consistency_altrts.txt\n",
      "extracting marks from:  eval_model_generations/gpt-3.5-turbo-0301/eval_M23_generations/consistency_altmcq.txt\n",
      "extracting marks from:  eval_model_generations/gpt-3.5-turbo-0301/eval_M23_generations/fluency_rts.txt\n",
      "extracting marks from:  eval_model_generations/gpt-3.5-turbo-0301/eval_M23_generations/fluency_mcq.txt\n",
      "extracting marks from:  eval_model_generations/gpt-3.5-turbo-0301/eval_M23_generations/fluency_stareval.txt\n",
      "extracting marks from:  eval_model_generations/gpt-3.5-turbo-0301/eval_M23_generations/fluency_altrts.txt\n",
      "extracting marks from:  eval_model_generations/gpt-3.5-turbo-0301/eval_M23_generations/fluency_altmcq.txt\n",
      "extracting marks from:  eval_model_generations/gpt-3.5-turbo-0301/eval_M23_generations/coherence_rts.txt\n",
      "extracting marks from:  eval_model_generations/gpt-3.5-turbo-0301/eval_M23_generations/coherence_mcq.txt\n",
      "extracting marks from:  eval_model_generations/gpt-3.5-turbo-0301/eval_M23_generations/coherence_stareval.txt\n",
      "extracting marks from:  eval_model_generations/gpt-3.5-turbo-0301/eval_M23_generations/coherence_altrts.txt\n",
      "extracting marks from:  eval_model_generations/gpt-3.5-turbo-0301/eval_M23_generations/coherence_altmcq.txt\n"
     ]
    }
   ],
   "source": [
    "!python extract_model_scores.py --eval_model gpt-3.5-turbo-0301"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Step 3.1: Calculate correlation for all 1200 summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval_model: gpt-3.5-turbo-0301\n",
      "eval_type: 0\n",
      "Evaluated model: gpt-3.5-turbo-0301\n",
      "Human metric: coherence\n",
      "Model metric: coherence_rts\n",
      "SignificanceResult(statistic=0.4436361681667084, pvalue=5.003789493069989e-59)\n",
      "PearsonRResult(statistic=0.4668832279911478, pvalue=5.365859162067621e-66)\n",
      "SignificanceResult(statistic=0.34939356951015704, pvalue=2.1790141884641815e-55)\n",
      "Human metric: consistency\n",
      "Model metric: consistency_rts\n",
      "SignificanceResult(statistic=0.42325454683118274, pvalue=2.3997467840493124e-53)\n",
      "PearsonRResult(statistic=0.5320097759439464, pvalue=1.2002776382392887e-88)\n",
      "SignificanceResult(statistic=0.37805810238133436, pvalue=5.568419916269254e-49)\n",
      "Human metric: fluency\n",
      "Model metric: fluency_rts\n",
      "SignificanceResult(statistic=0.2849295791449055, pvalue=7.542855714216993e-24)\n",
      "PearsonRResult(statistic=0.3018322792605033, pvalue=1.0707368512832981e-26)\n",
      "SignificanceResult(statistic=0.2397936259150923, pvalue=2.424290739393308e-23)\n",
      "Human metric: relevance\n",
      "Model metric: relevance_rts\n",
      "SignificanceResult(statistic=0.44789007142796516, pvalue=2.9103572954284474e-60)\n",
      "PearsonRResult(statistic=0.4630075081031612, pvalue=8.49890453029111e-65)\n",
      "SignificanceResult(statistic=0.35658288986345327, pvalue=5.650992653239566e-56)\n"
     ]
    }
   ],
   "source": [
    "!python calc_data_corr.py --eval_model gpt-3.5-turbo-0301 --eval_type 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Step 3.2: To Calculate correlation for each candidate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval_model: gpt-3.5-turbo-0301\n",
      "eval_type: 0\n",
      "per model corr values\n",
      "---------  -----------  -----------  -----------  -------------  -------------  -------------  ---------  ---------  ---------  -----------  -----------  -----------\n",
      "Candidate  coherence_S  coherence_P  coherence_K  consistency_S  consistency_P  consistency_K  fluency_S  fluency_P  fluency_K  relevance_S  relevance_P  relevance_K\n",
      "M8         0.42         0.383        0.323        0.229          0.273          0.209          0.274      0.245      0.236      0.519        0.509        0.438\n",
      "M9         0.174        0.243        0.142        0.119          0.265          0.103          0.256      0.258      0.219      0.254        0.307        0.2\n",
      "M10        0.365        0.415        0.292        0.305          0.452          0.251          0.258      0.288      0.223      0.367        0.378        0.284\n",
      "M11        0.378        0.42         0.32         0.404          0.488          0.335          0.227      0.288      0.182      0.501        0.511        0.394\n",
      "M12        0.208        0.237        0.16         0.087          0.02           0.082          0.086      0.107      0.071      0.438        0.451        0.354\n",
      "M13        0.455        0.473        0.359        0.178          0.037          0.167          0.063      0.151      0.055      0.403        0.403        0.329\n",
      "M14        0.433        0.467        0.355        0.114          0.187          0.105          -0.007     0.055      -0.005     0.421        0.435        0.336\n",
      "M15        0.372        0.385        0.279        0.189          0.316          0.177          0.1        0.087      0.085      0.252        0.288        0.193\n",
      "M17        0.291        0.32         0.233        -0.086         -0.061         -0.084         0.017      0.046      0.015      0.204        0.199        0.175\n",
      "M20        0.382        0.394        0.31         0.528          0.501          0.43           0.367      0.349      0.307      0.292        0.278        0.237\n",
      "M22        0.215        0.293        0.162        -0.072         -0.052         -0.07          -0.114     -0.131     -0.101     0.201        0.3          0.172\n",
      "M23        0.392        0.427        0.32         0.003          0.305          0.002          -0.078     -0.022     -0.069     0.223        0.324        0.184\n",
      "---------  -----------  -----------  -----------  -------------  -------------  -------------  ---------  ---------  ---------  -----------  -----------  -----------\n",
      "per model corr significance: * for p < 0.05\n",
      "---------  -----------  -----------  -----------  -------------  -------------  -------------  ---------  ---------  ---------  -----------  -----------  -----------\n",
      "Candidate  coherence_S  coherence_P  coherence_K  consistency_S  consistency_P  consistency_K  fluency_S  fluency_P  fluency_K  relevance_S  relevance_P  relevance_K\n",
      "M8         *            *            *            *              *              *              *          *          *          *            *            *\n",
      "M9                      *                                        *                             *          *          *          *            *            *\n",
      "M10        *            *            *            *              *              *              *          *          *          *            *            *\n",
      "M11        *            *            *            *              *              *              *          *          *          *            *            *\n",
      "M12        *            *            *                                                                                          *            *            *\n",
      "M13        *            *            *                                                                                          *            *            *\n",
      "M14        *            *            *                                                                                          *            *            *\n",
      "M15        *            *            *                           *                                                              *            *            *\n",
      "M17        *            *            *                                                                                          *            *            *\n",
      "M20        *            *            *            *              *              *              *          *          *          *            *            *\n",
      "M22        *            *            *                                                                                          *            *            *\n",
      "M23        *            *            *                           *                                                              *            *            *\n",
      "---------  -----------  -----------  -----------  -------------  -------------  -------------  ---------  ---------  ---------  -----------  -----------  -----------\n"
     ]
    }
   ],
   "source": [
    "!python per_model_corr.py --eval_model gpt-3.5-turbo-0301 --eval_type 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Step 3.3: Calculate meta-correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval_model: gpt-3.5-turbo-0301\n",
      "eval_type: 0\n",
      "meta-corr values\n",
      "------------------------  -----------  -----------  -----------  -------------  -------------  -------------  ---------  ---------  ---------  -----------  -----------  -----------\n",
      "Metric                    coherence_S  coherence_P  coherence_K  consistency_S  consistency_P  consistency_K  fluency_S  fluency_P  fluency_K  relevance_S  relevance_P  relevance_K\n",
      "rouge1_f                  0.0          -0.032       -0.091       -0.49          -0.527         -0.303         -0.42      -0.518     -0.273     -0.42        -0.387       -0.273\n",
      "rouge2_f                  0.559        0.508        0.485        -0.259         -0.48          -0.152         -0.217     -0.438     -0.152     -0.084       -0.12        -0.121\n",
      "rougel_f                  0.231        0.251        0.121        -0.51          -0.522         -0.303         -0.168     -0.412     -0.152     -0.224       -0.266       -0.121\n",
      "bert_score_f              -0.413       -0.403       -0.212       -0.58          -0.869         -0.424         -0.455     -0.663     -0.303     -0.685       -0.756       -0.515\n",
      "bart_score_src_hypo       -0.916       -0.747       -0.788       -0.266         -0.504         -0.121         0.154      0.123      0.182      -0.769       -0.837       -0.606\n",
      "bart_score_cnn_src_hypo   -0.748       -0.8         -0.636       -0.671         -0.913         -0.515         -0.51      -0.604     -0.485     -0.825       -0.852       -0.667\n",
      "bart_score_para_src_hypo  -0.72        -0.858       -0.606       -0.685         -0.888         -0.576         -0.294     -0.522     -0.212     -0.853       -0.88        -0.727\n",
      "gpt-3.5-turbo-0301        -0.042       -0.072       -0.121       -0.811         -0.751         -0.636         -0.748     -0.728     -0.606     -0.559       -0.473       -0.394\n",
      "------------------------  -----------  -----------  -----------  -------------  -------------  -------------  ---------  ---------  ---------  -----------  -----------  -----------\n",
      "meta-corr significance: * for p < 0.05\n",
      "------------------------  -----------  -----------  -----------  -------------  -------------  -------------  ---------  ---------  ---------  -----------  -----------  -----------\n",
      "Metric                    coherence_S  coherence_P  coherence_K  consistency_S  consistency_P  consistency_K  fluency_S  fluency_P  fluency_K  relevance_S  relevance_P  relevance_K\n",
      "rouge1_f\n",
      "rouge2_f                                            *\n",
      "rougel_f\n",
      "bert_score_f                                                     *              *                                        *                     *            *            *\n",
      "bart_score_src_hypo       *            *            *                                                                                          *            *            *\n",
      "bart_score_cnn_src_hypo   *            *            *            *              *              *                         *          *          *            *            *\n",
      "bart_score_para_src_hypo  *            *            *            *              *              *                                               *            *            *\n",
      "gpt-3.5-turbo-0301                                               *              *              *              *          *          *\n",
      "------------------------  -----------  -----------  -----------  -------------  -------------  -------------  ---------  ---------  ---------  -----------  -----------  -----------\n"
     ]
    }
   ],
   "source": [
    "!python calc_meta_corr.py --eval_model gpt-3.5-turbo-0301"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
